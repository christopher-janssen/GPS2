---
title: "Comparing Clustering Methods"
author: "Christopher Janssen"
date: "`r lubridate::today()`"
format:
  html:
    self-contained: true
editor_options:
  chunk_output_type: console
editor:
  markdown:
    wrap: 72
---

## Objectives

1.  Compare DBSCAN against the legacy algorithm at cumulative
    windows (Intake->FU1, Intake->FU2, Intake->FU3)
2.  Identify concordant, DBSCAN-unique, and legacy-unique locations
3.  Characterize where the methods agree and diverge

DBSCAN runs blind---legacy locations serve only as the comparison
target, temporally filtered to what was known at each window.

## Setup

```{r}
#| include: false

source(here::here("scripts/r/setup.R"))
source(here::here("scripts/r/clustering.R"))

library(geosphere)
library(furrr)
library(leaflet)
library(clue)

plan(multisession, workers = availableCores() - 1)

theme_set(theme_minimal())
```

## Parameters

```{r}
param_grid <- tibble(
  dwell_threshold = c(5, 5, 5, 5, 5, 10, 10, 10),
  eps_meters      = c(25, 50, 50, 75, 100, 50, 50, 75),
  min_pts         = c(2, 2, 3, 2, 2, 2, 3, 2)
)

param_grid |>
  mutate(set = row_number()) |>
  select(set, everything()) |>
  knitr::kable()

PROXIMITY_THRESHOLD <- 100
DEDUPE_THRESHOLD <- 50
```

## Data Loading

```{r}
study_dates <- read_csv(
  here::here(path_shared, "study_dates_gps.csv"),
  show_col_types = FALSE
) |>
  mutate(
    study_start = as_date(study_start),
    study_end = as_date(study_end)
  )

subids_dates <- study_dates |>
  pull(subid) |>
  unique()
```

```{r}
gps_data <- read_csv(
  here::here(path_gps2, "data/processed_gps.csv"),
  show_col_types = FALSE
) |>
  filter(subid %in% subids_dates)

nrow(gps_data)
```

```{r}
locs_gt <- read_csv(
  here::here(path_gps2, "data/locs_gt.csv"),
  show_col_types = FALSE
) |>
  mutate(
    subid = as.numeric(subid),
    utc_datetime = as.POSIXct(utc, origin = "1970-01-01", tz = "UTC")
  ) |>
  filter(subid %in% subids_dates)

nrow(locs_gt)
```

```{r}
visit_dates <- read_csv(
  here::here(path_shared, "visit_dates.csv"),
  show_col_types = FALSE
)
```

## Cumulative Windows

```{r}
visits_long <- visit_dates |>
  pivot_longer(
    cols = -subid,
    names_to = "visit_type",
    values_to = "visit_date"
  ) |>
  filter(!is.na(visit_date)) |>
  mutate(visit_date = as_date(visit_date))

intake_dates <- visits_long |>
  filter(str_detect(visit_type, "intake")) |>
  group_by(subid) |>
  slice_min(visit_date, n = 1, with_ties = FALSE) |>
  ungroup() |>
  select(subid, intake_date = visit_date)

followup_dates <- visits_long |>
  filter(!str_detect(visit_type, "intake")) |>
  group_by(subid) |>
  arrange(visit_date) |>
  mutate(fu_number = row_number()) |>
  ungroup() |>
  filter(fu_number <= 3)

cumulative_windows <- followup_dates |>
  select(subid, fu_number, window_end = visit_date) |>
  left_join(intake_dates, by = "subid") |>
  filter(!is.na(intake_date)) |>
  filter(subid %in% subids_dates)

cumulative_windows |>
  count(fu_number, name = "n_subjects") |>
  knitr::kable(col.names = c("Follow-Up Window", "N Subjects"))
```

## Stay Detection

```{r}
#| cache: true

unique_dwells <- unique(param_grid$dwell_threshold)

stays_by_threshold <- setNames(
  future_map(unique_dwells, function(dw) {
    detect_stays(gps_data, time_threshold = dw)
  }, .options = furrr_options(
    seed = TRUE,
    packages = c("dplyr", "geosphere")
  )),
  as.character(unique_dwells)
)

tibble(
  dwell_threshold = unique_dwells,
  n_stays = map_int(stays_by_threshold, nrow),
  n_subjects = map_int(stays_by_threshold, ~ n_distinct(.x$subid))
) |>
  knitr::kable()
```

## Pipeline

For each subject x window x parameter set: run DBSCAN, spatially
match against temporally-filtered legacy locations using bipartite
matching, and classify each location as concordant, DBSCAN-unique,
or legacy-unique.

```{r}
#| cache: true

tasks <- cumulative_windows |>
  crossing(param_grid |> mutate(param_id = row_number()))

nrow(tasks)
```

```{r}
#| cache: true

analyze_window <- function(sub, fu_num, window_end, intake_dt,
                           dwell_threshold, eps_meters, min_pts,
                           param_id,
                           stays_by_threshold, locs_gt,
                           proximity_m, dedupe_m) {
  stays <- stays_by_threshold[[as.character(dwell_threshold)]]

  stays_sub <- stays |>
    filter(subid == sub, as_date(start_time) <= window_end)

  if (nrow(stays_sub) < 2) return(NULL)

  # DBSCAN
  coords <- cbind(stays_sub$lon, stays_sub$lat)
  db <- run_dbscan(coords, eps = eps_meters, min_pts = min_pts)
  stays_sub <- stays_sub |> mutate(cluster = db$cluster)

  centroids <- if (db$n_clusters > 0 && any(db$cluster > 0)) {
    get_centroids(stays_sub, "cluster")
  } else {
    tibble(cluster_id = integer(), lat = double(), lon = double(),
           total_dwell_hrs = double(), n_stays = integer(),
           n_days = integer())
  }

  # legacy locations (temporally filtered + deduped + visitable)
  locs_sub <- locs_gt |> filter(subid == sub)
  locs_filtered <- temporally_filter_legacy(locs_sub, window_end)

  gt_deduped <- if (nrow(locs_filtered) > 0) {
    dedupe_locations(locs_filtered, threshold_m = dedupe_m) |>
      filter_visitable(stays_sub, threshold_m = proximity_m)
  } else {
    tibble(location_id = integer(), lat = double(), lon = double(),
           n_reports = integer(), intake = integer())
  }

  # bipartite matching
  match <- match_locations_bipartite(centroids, gt_deduped,
                                     threshold_m = proximity_m)

  n_concordant <- match$n_matched
  n_dbscan_only <- length(match$unmatched_a)
  n_legacy_only <- length(match$unmatched_b)
  n_total <- n_concordant + n_dbscan_only + n_legacy_only
  concordance <- if (n_total > 0) n_concordant / n_total else NA_real_

  tibble(
    subid = sub,
    fu_number = fu_num,
    window_end = window_end,
    param_id = param_id,
    dwell_threshold = dwell_threshold,
    eps_meters = eps_meters,
    min_pts = min_pts,
    n_dbscan = match$n_a,
    n_legacy = match$n_b,
    n_concordant = n_concordant,
    n_dbscan_only = n_dbscan_only,
    n_legacy_only = n_legacy_only,
    concordance = concordance
  )
}

results <- future_pmap_dfr(
  list(
    sub = tasks$subid,
    fu_num = tasks$fu_number,
    window_end = tasks$window_end,
    intake_dt = tasks$intake_date,
    dwell_threshold = tasks$dwell_threshold,
    eps_meters = tasks$eps_meters,
    min_pts = tasks$min_pts,
    param_id = tasks$param_id
  ),
  analyze_window,
  stays_by_threshold = stays_by_threshold,
  locs_gt = locs_gt,
  proximity_m = PROXIMITY_THRESHOLD,
  dedupe_m = DEDUPE_THRESHOLD,
  .options = furrr_options(
    seed = TRUE,
    packages = c("dplyr", "lubridate", "geosphere", "dbscan", "clue", "purrr")
  ),
  .progress = TRUE
)

nrow(results)
```

## Agreement Summary

```{r}
summary_table <- results |>
  group_by(fu_number, param_id, dwell_threshold, eps_meters,
           min_pts) |>
  summarize(
    n_subjects = n(),
    mean_concordance = mean(concordance, na.rm = TRUE),
    sd_concordance = sd(concordance, na.rm = TRUE),
    mean_concordant = mean(n_concordant),
    mean_dbscan_only = mean(n_dbscan_only),
    mean_legacy_only = mean(n_legacy_only),
    mean_n_dbscan = mean(n_dbscan),
    mean_n_legacy = mean(n_legacy),
    .groups = "drop"
  )
```

### Best Parameters per Window

```{r}
best_per_window <- summary_table |>
  group_by(fu_number) |>
  slice_max(mean_concordance, n = 1, with_ties = FALSE) |>
  ungroup()

best_per_window |>
  select(fu_number, dwell_threshold, eps_meters, min_pts,
         n_subjects, mean_concordance, sd_concordance) |>
  knitr::kable(
    digits = 3,
    col.names = c("FU", "Dwell", "Eps", "MinPts",
                  "N", "Concordance", "SD")
  )
```

### Overall Best Parameter Set

```{r}
overall_best <- summary_table |>
  group_by(param_id, dwell_threshold, eps_meters, min_pts) |>
  summarize(
    overall_concordance = mean(mean_concordance),
    .groups = "drop"
  ) |>
  slice_max(overall_concordance, n = 1, with_ties = FALSE)

best_results <- results |>
  semi_join(overall_best,
            by = c("dwell_threshold", "eps_meters", "min_pts"))

overall_best |>
  knitr::kable(digits = 3)
```

### Full Comparison Table

```{r}
summary_table |>
  mutate(
    params = paste0("d=", dwell_threshold,
                    " e=", eps_meters,
                    " m=", min_pts)
  ) |>
  select(fu_number, params, n_subjects,
         mean_concordance, mean_concordant,
         mean_dbscan_only, mean_legacy_only) |>
  arrange(fu_number, desc(mean_concordance)) |>
  knitr::kable(
    digits = 2,
    col.names = c("FU", "Params", "N", "Concordance",
                  "Concordant", "DBSCAN Only", "Legacy Only")
  )
```

## Concordance Heatmap

```{r}
#| fig-width: 12
#| fig-height: 9
summary_table |>
  mutate(fu_label = paste0("FU", fu_number)) |>
  ggplot(aes(x = factor(eps_meters), y = factor(min_pts),
             fill = mean_concordance)) +
  geom_tile(color = "white", linewidth = 0.5) +
  geom_text(aes(label = sprintf("%.2f", mean_concordance)),
            size = 3) +
  scale_fill_viridis_c(labels = scales::percent,
                       limits = c(0, 1),
                       option = "magma", direction = -1) +
  facet_grid(rows = vars(fu_label),
             cols = vars(dwell_threshold),
             labeller = labeller(
               dwell_threshold = \(x) paste0(x, " min")
             )) +
  labs(
    title = "Concordance Rate: eps x minPts",
    subtitle = "Faceted by dwell threshold (cols) and window (rows)",
    x = "eps (meters)",
    y = "minPts",
    fill = "Concordance"
  ) +
  theme(legend.position = "bottom")
```

## Location Agreement by Window

Stacked bar showing mean counts of concordant, DBSCAN-unique, and
legacy-unique locations at each window (overall best params).

```{r}
#| fig-width: 10
#| fig-height: 6

best_results |>
  group_by(fu_number) |>
  summarize(
    Concordant = mean(n_concordant),
    `DBSCAN Only` = mean(n_dbscan_only),
    `Legacy Only` = mean(n_legacy_only),
    .groups = "drop"
  ) |>
  pivot_longer(-fu_number, names_to = "category",
               values_to = "mean_count") |>
  mutate(
    category = factor(category,
                      levels = c("Concordant", "Legacy Only",
                                 "DBSCAN Only")),
    fu_label = paste0("FU", fu_number)
  ) |>
  ggplot(aes(x = fu_label, y = mean_count, fill = category)) +
  geom_col(position = "stack", alpha = 0.8) +
  scale_fill_manual(
    values = c(Concordant = "#2ca02c",
               `Legacy Only` = "#d62728",
               `DBSCAN Only` = "#1f77b4")
  ) +
  labs(
    title = "Mean Location Counts by Agreement Category",
    subtitle = paste0("Params: dwell=", overall_best$dwell_threshold,
                      ", eps=", overall_best$eps_meters,
                      ", minPts=", overall_best$min_pts),
    x = "Follow-Up Window",
    y = "Mean Locations per Subject",
    fill = NULL
  )
```

### Per-Subject Boxplots

```{r}
#| fig-width: 12
#| fig-height: 6

best_results |>
  select(subid, fu_number, n_concordant, n_dbscan_only,
         n_legacy_only) |>
  pivot_longer(cols = c(n_concordant, n_dbscan_only,
                        n_legacy_only),
               names_to = "category", values_to = "count") |>
  mutate(
    category = case_match(category,
      "n_concordant" ~ "Concordant",
      "n_dbscan_only" ~ "DBSCAN Only",
      "n_legacy_only" ~ "Legacy Only"
    ),
    category = factor(category,
                      levels = c("Concordant", "Legacy Only",
                                 "DBSCAN Only")),
    fu_label = paste0("FU", fu_number)
  ) |>
  ggplot(aes(x = category, y = count, fill = category)) +
  geom_boxplot(width = 0.6, alpha = 0.7, outlier.alpha = 0.4) +
  geom_jitter(width = 0.15, alpha = 0.2, size = 1) +
  scale_fill_manual(
    values = c(Concordant = "#2ca02c",
               `Legacy Only` = "#d62728",
               `DBSCAN Only` = "#1f77b4")
  ) +
  facet_wrap(~ fu_label) +
  labs(
    title = "Per-Subject Location Counts by Category",
    x = NULL,
    y = "Count per Subject"
  ) +
  theme(legend.position = "none")
```

## Legacy-Unique Breakdown: Intake vs Algorithm

Among locations found by legacy but not DBSCAN---are they
intake-reported (possibly never visited) or algorithm-derived?

```{r}
#| cache: true

overlap_details <- future_pmap_dfr(
  list(
    sub = cumulative_windows$subid,
    fu_num = cumulative_windows$fu_number,
    window_end = cumulative_windows$window_end
  ),
  function(sub, fu_num, window_end,
           stays_by_threshold, locs_gt, best,
           proximity_m, dedupe_m) {
    dw <- best$dwell_threshold
    eps <- best$eps_meters
    mpts <- best$min_pts

    stays <- stays_by_threshold[[as.character(dw)]]
    stays_sub <- stays |>
      filter(subid == sub, as_date(start_time) <= window_end)

    if (nrow(stays_sub) < 2) return(NULL)

    coords <- cbind(stays_sub$lon, stays_sub$lat)
    db <- run_dbscan(coords, eps = eps, min_pts = mpts)
    stays_sub <- stays_sub |> mutate(cluster = db$cluster)

    if (db$n_clusters == 0 || !any(db$cluster > 0)) return(NULL)

    centroids <- get_centroids(stays_sub, "cluster")

    locs_sub <- locs_gt |> filter(subid == sub)
    locs_filtered <- temporally_filter_legacy(locs_sub, window_end)
    if (nrow(locs_filtered) == 0) return(NULL)
    gt_deduped <- dedupe_locations(locs_filtered,
                                   threshold_m = dedupe_m) |>
      filter_visitable(stays_sub, threshold_m = proximity_m)
    if (nrow(gt_deduped) == 0) return(NULL)

    match <- match_locations_bipartite(centroids, gt_deduped,
                                       threshold_m = proximity_m)

    fn_locs <- gt_deduped[match$unmatched_b, ]

    tibble(
      subid = sub,
      fu_number = fu_num,
      n_concordant = match$n_matched,
      n_legacy_only = length(match$unmatched_b),
      n_dbscan_only = length(match$unmatched_a),
      n_fn_intake = sum(fn_locs$intake == 1),
      n_fn_algorithm = sum(fn_locs$intake == 0)
    )
  },
  stays_by_threshold = stays_by_threshold,
  locs_gt = locs_gt,
  best = overall_best,
  proximity_m = PROXIMITY_THRESHOLD,
  dedupe_m = DEDUPE_THRESHOLD,
  .options = furrr_options(
    seed = TRUE,
    packages = c("dplyr", "lubridate", "geosphere", "dbscan", "clue", "purrr")
  ),
  .progress = TRUE
)
```

```{r}
overlap_details |>
  group_by(fu_number) |>
  summarize(
    n_subjects = n(),
    mean_concordant = mean(n_concordant),
    mean_legacy_only = mean(n_legacy_only),
    mean_dbscan_only = mean(n_dbscan_only),
    mean_fn_intake = mean(n_fn_intake),
    mean_fn_algorithm = mean(n_fn_algorithm),
    .groups = "drop"
  ) |>
  knitr::kable(
    digits = 2,
    col.names = c("FU", "N", "Concordant", "Legacy Only",
                  "DBSCAN Only", "Legacy Only (Intake)",
                  "Legacy Only (Algorithm)")
  )
```

## Per-Subject Maps

```{r}
map_comparison <- function(sub, fu_num,
                           stays_by_threshold, locs_gt,
                           cumulative_windows, best_row,
                           proximity_m, dedupe_m) {
  window_row <- cumulative_windows |>
    filter(subid == sub, fu_number == fu_num)
  if (nrow(window_row) == 0) return(NULL)
  window_end <- window_row$window_end

  stays <- stays_by_threshold[[as.character(best_row$dwell_threshold)]]
  stays_sub <- stays |>
    filter(subid == sub, as_date(start_time) <= window_end)

  if (nrow(stays_sub) < 2) return(NULL)

  coords <- cbind(stays_sub$lon, stays_sub$lat)
  db <- run_dbscan(coords, eps = best_row$eps_meters,
                   min_pts = best_row$min_pts)
  stays_sub <- stays_sub |> mutate(cluster = db$cluster)

  centroids <- if (db$n_clusters > 0 && any(db$cluster > 0)) {
    get_centroids(stays_sub, "cluster")
  } else {
    tibble(cluster_id = integer(), lat = double(),
           lon = double(), total_dwell_hrs = double(),
           n_stays = integer(), n_days = integer())
  }

  locs_sub <- locs_gt |> filter(subid == sub)
  locs_filtered <- temporally_filter_legacy(locs_sub, window_end)
  gt_deduped <- if (nrow(locs_filtered) > 0) {
    dedupe_locations(locs_filtered, threshold_m = dedupe_m) |>
      filter_visitable(stays_sub, threshold_m = proximity_m)
  } else {
    tibble(location_id = integer(), lat = double(),
           lon = double(), n_reports = integer(),
           intake = integer())
  }

  match <- match_locations_bipartite(centroids, gt_deduped,
                                     threshold_m = proximity_m)

  m <- leaflet() |>
    addProviderTiles(providers$CartoDB.Positron)

  # stays
  stay_colors <- if_else(stays_sub$cluster == 0,
                         "#999999", "#3388ff")
  m <- m |>
    addCircleMarkers(
      lng = stays_sub$lon, lat = stays_sub$lat,
      radius = 3, color = stay_colors, fillOpacity = 0.4,
      stroke = FALSE, group = "Stays",
      popup = paste0(
        "Stay #", stays_sub$stay_id,
        "<br>Dwell: ", round(stays_sub$dwell_mins, 1), " min",
        "<br>Cluster: ", stays_sub$cluster
      )
    )

  # DBSCAN centroids: concordant (blue) vs unique (orange)
  if (nrow(centroids) > 0) {
    colors <- rep("#FF8C00", nrow(centroids))
    colors[match$matched_a] <- "#0000FF"
    labels <- rep("DBSCAN only", nrow(centroids))
    labels[match$matched_a] <- "Concordant (DBSCAN)"

    m <- m |>
      addCircleMarkers(
        lng = centroids$lon, lat = centroids$lat,
        radius = 8, color = colors, fillOpacity = 0.7,
        weight = 2, group = "DBSCAN Centroids",
        popup = paste0(
          labels,
          "<br>Cluster #", centroids$cluster_id,
          "<br>Stays: ", centroids$n_stays,
          "<br>Days: ", centroids$n_days,
          "<br>Dwell: ",
          round(centroids$total_dwell_hrs * 60, 1), " min"
        )
      )
  }

  # legacy locations: concordant (green) vs unique (red)
  if (nrow(gt_deduped) > 0) {
    colors <- rep("red", nrow(gt_deduped))
    colors[match$matched_b] <- "green"
    labels <- rep("Legacy only", nrow(gt_deduped))
    labels[match$matched_b] <- "Concordant (Legacy)"

    m <- m |>
      addMarkers(
        lng = gt_deduped$lon, lat = gt_deduped$lat,
        group = "Legacy Locations",
        icon = awesomeIcons(
          icon = "ios-close", iconColor = "white",
          library = "ion", markerColor = colors
        ),
        popup = paste0(
          labels,
          "<br>Location #", gt_deduped$location_id,
          "<br>Reports: ", gt_deduped$n_reports,
          "<br>Intake: ", gt_deduped$intake
        )
      )
  }

  m |>
    addLayersControl(
      overlayGroups = c("Stays", "DBSCAN Centroids",
                        "Legacy Locations"),
      options = layersControlOptions(collapsed = FALSE)
    )
}
```

### Example Maps

```{r}
last_fu <- max(best_results$fu_number)

subject_concordance <- best_results |>
  filter(fu_number == last_fu) |>
  arrange(concordance)

n_subs <- nrow(subject_concordance)
example_subs <- c(
  subject_concordance$subid[n_subs],
  subject_concordance$subid[ceiling(n_subs / 2)],
  subject_concordance$subid[1]
)
example_labels <- c("High Agreement", "Median Agreement",
                    "Low Agreement")
```

```{r}
for (i in seq_along(example_subs)) {
  cat("\n###", example_labels[i],
      "(subid:", example_subs[i], ")\n\n")
  print(
    map_comparison(
      sub = example_subs[i],
      fu_num = last_fu,
      stays_by_threshold = stays_by_threshold,
      locs_gt = locs_gt,
      cumulative_windows = cumulative_windows,
      best_row = overall_best,
      proximity_m = PROXIMITY_THRESHOLD,
      dedupe_m = DEDUPE_THRESHOLD
    )
  )
}
```

## Robustness

### Concordance Stability Across Parameter Sets

```{r}
summary_table |>
  group_by(fu_number) |>
  summarize(
    min = min(mean_concordance),
    q25 = quantile(mean_concordance, 0.25),
    median = median(mean_concordance),
    q75 = quantile(mean_concordance, 0.75),
    max = max(mean_concordance),
    .groups = "drop"
  ) |>
  knitr::kable(digits = 3)
```

### Concordance Over Windows by Parameter Set

```{r}
#| fig-width: 10
#| fig-height: 6

summary_table |>
  mutate(
    params = paste0("d=", dwell_threshold,
                    " e=", eps_meters,
                    " m=", min_pts)
  ) |>
  ggplot(aes(x = fu_number, y = mean_concordance,
             color = params, group = params)) +
  geom_line(linewidth = 0.8) +
  geom_point(size = 2) +
  scale_x_continuous(breaks = 1:3, labels = paste0("FU", 1:3)) +
  scale_y_continuous(labels = scales::percent,
                     limits = c(0, 1)) +
  labs(
    title = "Concordance Across Windows by Parameter Set",
    x = "Follow-Up Window",
    y = "Mean Concordance",
    color = "Parameters"
  ) +
  theme(legend.position = "bottom")
```

## Diagnostics

### Legacy Location Counts by Window

Validates temporal filtering: counts should increase from
FU1 to FU3.

```{r}
legacy_counts <- future_pmap_dfr(
  list(
    sub = cumulative_windows$subid,
    fu_num = cumulative_windows$fu_number,
    window_end = cumulative_windows$window_end
  ),
  function(sub, fu_num, window_end, locs_gt,
           stays_by_threshold, dwell_threshold,
           proximity_m, dedupe_m) {
    stays <- stays_by_threshold[[as.character(dwell_threshold)]]
    stays_sub <- stays |>
      filter(subid == sub, as_date(start_time) <= window_end)

    locs_sub <- locs_gt |> filter(subid == sub)
    locs_filtered <- temporally_filter_legacy(locs_sub,
                                              window_end)
    gt_deduped <- if (nrow(locs_filtered) > 0 &&
                      nrow(stays_sub) > 0) {
      dedupe_locations(locs_filtered, threshold_m = dedupe_m) |>
        filter_visitable(stays_sub, threshold_m = proximity_m)
    } else {
      tibble()
    }
    tibble(subid = sub, fu_number = fu_num,
           n_legacy = nrow(gt_deduped))
  },
  locs_gt = locs_gt,
  stays_by_threshold = stays_by_threshold,
  dwell_threshold = overall_best$dwell_threshold,
  proximity_m = PROXIMITY_THRESHOLD,
  dedupe_m = DEDUPE_THRESHOLD,
  .options = furrr_options(
    seed = TRUE,
    packages = c("dplyr", "lubridate", "geosphere", "dbscan", "clue", "purrr")
  ),
  .progress = TRUE
)

legacy_counts |>
  group_by(fu_number) |>
  summarize(
    n_subjects = n(),
    mean = mean(n_legacy),
    median = median(n_legacy),
    min = min(n_legacy),
    max = max(n_legacy),
    .groups = "drop"
  ) |>
  knitr::kable(
    digits = 1,
    col.names = c("FU", "N Subjects", "Mean", "Median",
                  "Min", "Max")
  )
```

### Sample Size by Window

```{r}
cumulative_windows |>
  count(fu_number, name = "n_subjects") |>
  ggplot(aes(x = factor(fu_number), y = n_subjects)) +
  geom_col(fill = "steelblue", alpha = 0.7) +
  labs(
    title = "Sample Size at Each Follow-Up Window",
    x = "Follow-Up Window",
    y = "Number of Subjects"
  )
```

### DBSCAN Cluster Count by Window

```{r}
best_results |>
  group_by(fu_number) |>
  summarize(
    mean = mean(n_dbscan),
    median = median(n_dbscan),
    min = min(n_dbscan),
    max = max(n_dbscan),
    .groups = "drop"
  ) |>
  knitr::kable(
    digits = 1,
    col.names = c("FU", "Mean", "Median", "Min", "Max")
  )
```

## Save Results

```{r}
write_csv(
  results,
  here::here(path_gps2, "data/cluster_comp_v2_results.csv")
)
```
