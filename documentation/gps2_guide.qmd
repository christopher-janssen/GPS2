---
title: "GPS2: Privacy-Compliant GPS Analysis System"
subtitle: "Complete Setup and Usage Guide"
author: "Christopher Janssen"
format:
  html:
    toc: true
    toc-depth: 3
    code-fold: false
    theme: flatly
    embed-resources: true
editor: visual
---

## Overview

GPS2 is a privacy-compliant spatial analysis system for addiction recovery research. The system processes GPS coordinates from study participants to automatically identify venue types and behavioral patterns while maintaining strict data privacy through local infrastructure.

### Key Features

-   **Privacy-by-design**: All sensitive GPS data remains within controlled local infrastructure
-   **Automated clustering**: Identifies meaningful locations based on duration and proximity
-   **Local geocoding**: Converts coordinates to addresses without external API calls
-   **Interactive visualization**: Creates detailed maps of participant movement patterns
-   **Scalable processing**: Handles large datasets efficiently through PostGIS spatial database

## System Requirements

### Minimum Hardware

-   8GB RAM (16GB recommended for large datasets)
-   10GB free disk space
-   Multi-core processor (4+ cores recommended)

### Software Prerequisites

-   **Docker Desktop**: For containerized PostGIS and Nominatim services
-   **R (4.0+)**: With Tidyverse packages installed
-   **RStudio**: Recommended for development

### Operating System Support

-   **macOS**: Tested on macOS 10.15+
-   **Linux**: Ubuntu 18.04+, other distributions should work
-   **Windows**: Windows 10+ with WSL2 enabled for Docker

## Initial Setup

### 1. Environment Configuration

``` bash
# First-time setup: Copy and configure environment file
cp .env.example .env
# Edit .env to set RESEARCH_DATA_PATH for your operating system
```

### 2. Docker Setup

Ensure Docker Desktop is installed and running on your system.

``` bash
# Verify Docker installation
docker --version
docker-compose --version
```

### 3. Environment Bootstrap

``` r
# Bootstrap the entire GPS2 environment (installs packages + sets up containers)
source("scripts/r/bootstrap.R")
bootstrap_gps2_environment()
```

This single command will:

-   Install all required R packages automatically
-   Start Docker containers (PostGIS and Nominatim)
-   Initialize PostGIS database with proper schema
-   Create all necessary tables
-   Verify system functionality

The bootstrap process takes 2-3 minutes on first run as Docker downloads images and initializes the spatial database.

## Data Processing Workflow

### Step 1: Docker Database Management

``` bash
# Start PostGIS and Nominatim containers
cd docker-postgis && docker-compose up -d

# Connect to database directly
./scripts/bash/connect_db.sh  # Mac/Linux
# Windows: Use Docker Desktop GUI or docker exec -it gps2_geocoding psql -U gps2_researcher -d gps2_geocoding

# Stop containers when finished
cd docker-postgis && docker-compose down
```

### Step 2: Load GPS Data

``` r
# Load GPS data using main entry point
source("scripts/r/data_operations.R")
load_gps_data_to_postgis("data/sample_data.csv")

# Alternative: Complete workflow with clustering and geocoding
process_gps_data_complete("data/sample_data.csv", run_clustering = TRUE, run_geocoding = TRUE)
```

### Step 3: Cluster Analysis

``` r
# Load analysis functions
source("scripts/r/analysis.R")

# Run clustering for all participants (eps = radius in meters)
all_clusters <- cluster_all_participants_db(eps = 50)

# Alternative: Use data operations workflow (includes database insertion)
source("scripts/r/data_operations.R")
cluster_all_participants(eps = 50)

# Check clustering results
source("scripts/r/database.R")
summary <- get_database_summary()
print(summary)
```

### Step 4: Reverse Geocoding (Optional)

The system includes local geocoding capabilities that convert GPS coordinates to addresses without transmitting data to external services.

``` r
# Wait for Nominatim service to be ready (first run takes 10-15 minutes)
test_nominatim_with_retry()

# Run reverse geocoding for all clusters
reverse_geocode_clusters_db()

# Check geocoding success rates
coverage <- analyze_geocoding_coverage_db()
```

### Step 5: Visualization and Analysis

``` r
# Load visualization functions
source("scripts/r/visualization.R")

# Create cluster maps for specific participants
cluster_map <- map_participant_clusters(participant_id = 19)
save_map(cluster_map, "participant_19_clusters")

# Create geocoded location maps (if geocoding completed)
geocoded_map <- map_participant_geocoded(participant_id = 19)
save_map(geocoded_map, "participant_19_geocoded")

# Generate maps for multiple participants
generate_participant_maps(
  participant_ids = c(19, 56, 65), 
  map_type = "clusters", 
  save_maps = TRUE
)
```

## Core Functions Reference

### Database Operations

``` r
source("scripts/r/database.R")

# Single connection point
con <- connect_gps2_db()               # Main connection function
result <- query_gps2_db("SELECT * FROM gps2.participants LIMIT 5")

# Transaction management
with_gps2_transaction({
  # Multiple database operations here
  insert_gps_batch(gps_data)
  insert_cluster_data(cluster_results)
})

# System health checks
check_gps2_system()                    # Verify containers and connections
```

### Data Processing

``` r
source("scripts/r/data_operations.R")
source("scripts/r/gps_processing.R")

# Main entry point for CSV import
load_gps_data_to_postgis("path/to/tracks.csv")

# Core GPS processing function
process_gps(gps_data)                  # Noise filtering and movement classification
get_stationary(processed_data)         # Extract stationary points

# Batch processing functions
insert_gps_batch(gps_data)            # Efficient batch insertion
insert_cluster_data(cluster_results)   # Insert clustering results
```

### Analysis Functions

``` r
source("scripts/r/analysis.R")

# Duration-based clustering (environment version - data already loaded)
cluster_stationary_gps_env(gps_data, participant_id, eps = 50)

# Duration-based clustering (database version - queries database)
cluster_stationary_gps_db(participant_id, eps = 50)
cluster_all_participants_db(eps = 50)  # Process all participants

# Geocoding
test_nominatim_with_retry()            # Test with retry logic
reverse_geocode_clusters_db(participant_ids = c(19, 56))
get_geocoded_clusters_db(participant_ids = 19)
analyze_geocoding_coverage_db()        # Success rate analysis
```

### Visualization

``` r
source("scripts/r/visualization.R")

# Main visualization functions
visualize_gps_db(19, "clusters")       # Database version - clusters
visualize_gps_db(19, "raw")            # Database version - raw GPS
visualize_gps_env(data, 19, "clusters") # Environment version - from loaded data

# Convenience functions
map_participant_clusters(19)           # Quick cluster map
map_participant_gps(19)                # Quick GPS map  
map_participant_geocoded(19)           # Same as clusters (geocoding included)

# Batch processing
generate_participant_maps(c(19, 56), "clusters", save_maps = TRUE)

# Utilities
get_participant_summary(19)            # Statistics summary
save_map(map_object, "filename")       # Save to HTML file
```

## Advanced Usage

### Configuration System

All settings are centralized in `config/gps2_config.R`:

``` r
source("config/gps2_config.R")
config <- get_config()

# View current configuration
print(config$clustering)  # eps=50, min_duration=30min
print(config$speed)       # stationary=4mph, max=100mph
print(config$database)    # batch sizes and timeouts
```

### Custom Clustering Parameters

``` r
# More restrictive clustering (smaller radius)
clusters_strict <- cluster_all_participants_db(eps = 25)

# More permissive clustering (larger radius)
clusters_loose <- cluster_all_participants_db(eps = 100)
```

### Utility Functions

``` r
# Load all utilities at once
source("utils/load_all_utils.R")
load_gps2_utils()  # Auto-sources all utility files

# Individual utility modules available in utils/ directory
```

### Custom Database Queries

``` r
# Find participants with many locations
high_activity <- query_gps2_db("
  SELECT subid, COUNT(*) as cluster_count 
  FROM gps2.location_clusters 
  GROUP BY subid 
  HAVING COUNT(*) >= 10 
  ORDER BY cluster_count DESC;
")

# Find routine locations across all participants
routine_locations <- query_gps2_db("
  SELECT * FROM gps2.location_clusters 
  WHERE unique_days >= 5 AND total_visits >= 8
  ORDER BY total_duration_hours DESC;
")
```

### Batch Processing Multiple Files

``` r
# Process multiple GPS files
gps_files <- list.files("data/", pattern = "*.csv", full.names = TRUE)

for (file in gps_files) {
  cat("Processing", file, "\n")
  load_gps_data_to_postgis(file, clear_existing = FALSE)
}
```

## Privacy and Security

### Data Protection Features

-   **Local processing**: All GPS coordinates remain within your controlled infrastructure
-   **No external transmissions**: Geocoding uses local OpenStreetMap data (Wisconsin-only)
-   **Isolated environment**: Docker containers provide process isolation
-   **Volume mount security**: Data accessed via `/research_data` mount (configured via RESEARCH_DATA_PATH in .env)
-   **Audit trail**: All database operations are logged

### For External Collaborators

If sharing this system with external collaborators:

1.  **Data sharing**: Only share the code repository, never the processed data
2.  **Container isolation**: Each installation creates independent databases
3.  **No data persistence**: Collaborators work with their own GPS datasets
4.  **Clean setup**: Use `bootstrap_gps2_environment(force_recreate = TRUE)` for fresh installations

## Troubleshooting

### Common Issues

**Docker containers not starting:**

``` bash
# Check Docker status
cd docker-postgis
docker-compose ps

# Restart services
docker-compose down -v
docker-compose up -d
```

**Database connection errors:**

``` r
# Verify system status
check_gps2_system()

# Test connection directly
con <- connect_gps2_db()
DBI::dbGetInfo(con)
```

**Nominatim geocoding failures:**

``` r
# Test service availability
test_nominatim_with_retry()  # Tests with automatic retry logic

# Check container logs
# In terminal: docker-compose logs nominatim
```

**Memory issues with large datasets:**

``` r
# Process data in smaller batches
participant_batches <- split(participant_ids, ceiling(seq_along(participant_ids)/10))
for (batch in participant_batches) {
  cluster_all_participants_db(participant_ids = batch)
}
```

### Performance Optimization

**For large datasets:** - Increase Docker memory allocation (Docker Desktop → Settings → Resources) - Process participants in smaller batches - Consider running overnight for initial processing

**For faster geocoding:**

``` r
# Adjust batch processing (be careful not to overwhelm system)
reverse_geocode_clusters_db(batch_size = 50)  # Larger batches for faster processing
```

## Project Structure

```         
GPS2/
├── docker-postgis/
│   ├── docker-compose.yml           # Container configuration
│   └── init-scripts/
│       └── 01-setup-postgis.sql     # Database schema
├── scripts/r/
│   ├── bootstrap.R                  # Environment setup
│   ├── database.R                   # Connection management
│   ├── data_operations.R            # Data insertion/updates
│   ├── analysis.R                   # Clustering & geocoding
│   ├── visualization.R              # Mapping functions
│   └── gps_processing.R             # GPS filtering
├── scripts/bash/
│   └── connect_db.sh                # Database connection script
├── utils/                           # Modular utility functions
│   └── load_all_utils.R             # Auto-loader for utilities
├── config/
│   └── gps2_config.R                # Centralized configuration
├── GPS/data/
│   └── sample_data.csv              # Sample GPS data
├── documentation/
│   └── gps2_guide.qmd               # This comprehensive guide
└── maps/                            # Generated visualizations
```

## Expected Processing Times

-   **Initial setup**: 2-3 minutes
-   **GPS data loading**: 1-2 minutes per 10,000 points
-   **Clustering analysis**: 30 seconds per participant
-   **Nominatim setup**: 10-15 minutes (first run only)
-   **Reverse geocoding**: 2-3 minutes per 100 locations

## Next Steps

After completing this guide, you should have:

-   A fully functional GPS2 environment
-   GPS data loaded and clustered
-   Interactive maps of participant locations
-   Optional geocoded address information

For ongoing analysis, the system supports:

-   Adding new GPS datasets
-   Refining clustering parameters
-   Creating custom visualizations
-   Exporting results for statistical analysis
